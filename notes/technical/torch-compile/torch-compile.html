<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Torch Compiler</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-default_background {
	color: rgba(50, 48, 44, 1);
}
.highlight-gray_background {
	background: rgba(248, 248, 247, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(248, 243, 252, 1);
}
.highlight-pink_background {
	background: rgba(252, 241, 246, 1);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(248, 248, 247, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(248, 243, 252, 1);
}
.block-color-pink_background {
	background: rgba(252, 241, 246, 1);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: undefined; }
.select-value-color-pink { background-color: rgba(225, 136, 179, 0.27); }
.select-value-color-purple { background-color: rgba(168, 129, 197, 0.27); }
.select-value-color-green { background-color: rgba(123, 183, 129, 0.27); }
.select-value-color-gray { background-color: rgba(84, 72, 49, 0.15); }
.select-value-color-transparentGray { background-color: undefined; }
.select-value-color-translucentGray { background-color: undefined; }
.select-value-color-orange { background-color: rgba(224, 124, 57, 0.27); }
.select-value-color-brown { background-color: rgba(210, 162, 141, 0.35); }
.select-value-color-red { background-color: rgba(244, 171, 159, 0.4); }
.select-value-color-yellow { background-color: rgba(236, 191, 66, 0.39); }
.select-value-color-blue { background-color: rgba(93, 165, 206, 0.27); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="1c1c8bb5-c4a2-805c-b0a0-ebe0ffa724c7" class="page sans"><header><h1 class="page-title">Torch Compiler</h1><p class="page-description"></p></header><div class="page-body"><h2 id="1c1c8bb5-c4a2-804d-a7d7-d084de5b5e47" class=""><mark class="highlight-teal">Contents</mark></h2><ol type="1" id="1c1c8bb5-c4a2-80f8-8311-e499d8fd71a5" class="numbered-list" start="1"><li>TorchDynamo (Tracing)</li></ol><ol type="1" id="1c1c8bb5-c4a2-8087-844b-d4762295a419" class="numbered-list" start="2"><li>TorchInductor (Compiling)</li></ol><ol type="1" id="1c1c8bb5-c4a2-80dc-bafd-f896a339a22a" class="numbered-list" start="3"><li>CUDA Graphs (Kernel Batching)</li></ol><h2 id="1c1c8bb5-c4a2-8042-b594-cbf40f35fd74" class=""><mark class="highlight-red">High-Level</mark></h2><ol type="1" id="1c1c8bb5-c4a2-8067-b274-fa66ac2c6b27" class="numbered-list" start="1"><li>Extract computation graph.<ul id="1c1c8bb5-c4a2-80c1-b839-fa8feb81b6a7" class="bulleted-list"><li style="list-style-type:disc"><strong>Dynamo</strong> traces function into an FX Graph</li></ul></li></ol><ol type="1" id="1c1c8bb5-c4a2-80ba-ad21-dd4555bb3152" class="numbered-list" start="2"><li>Compile graph into optimized functions.<ul id="1c1c8bb5-c4a2-80c3-be72-f3657d239fc2" class="bulleted-list"><li style="list-style-type:disc"><strong>Inductor </strong>compiles the FX Graph into efficient Triton kernels</li></ul></li></ol><ol type="1" id="1c1c8bb5-c4a2-80dd-9345-d191e7bc2217" class="numbered-list" start="3"><li>Assemble into a new function.<ul id="1c1c8bb5-c4a2-80aa-a375-fe01d6244e9f" class="bulleted-list"><li style="list-style-type:disc">Bytecode of the function is rewritten to call the compiled function</li></ul><ul id="1c1c8bb5-c4a2-80ec-b6c6-f249a06680c8" class="bulleted-list"><li style="list-style-type:disc">Give function to CPython to run it</li></ul></li></ol><ol type="1" id="1c1c8bb5-c4a2-8049-8098-fff9a322164a" class="numbered-list" start="4"><li>Capture CUDA graphs.<ul id="1c1c8bb5-c4a2-8073-83a1-de46f5f0b51e" class="bulleted-list"><li style="list-style-type:disc">Record sequence of kernels (stream) invoked by compiled function</li></ul><ul id="1c1c8bb5-c4a2-802b-b2eb-ecc5aae0395c" class="bulleted-list"><li style="list-style-type:disc">Group kernels that can be launched together (this is a CUDA graph)</li></ul></li></ol><h1 id="1c1c8bb5-c4a2-806f-915d-e4178cde9035" class=""><mark class="highlight-blue">1. Torch Dynamo</mark></h1><h3 id="1c1c8bb5-c4a2-80be-80ea-f7c137f1554b" class=""><mark class="highlight-red">Process</mark></h3><ol type="1" id="1c1c8bb5-c4a2-8085-bba7-dca95eb71613" class="numbered-list" start="1"><li>Dynamo traces function into an FX graph.<ol type="a" id="1c1c8bb5-c4a2-8032-ae57-feb5545ee42e" class="numbered-list" start="1"><li>Pass the FX Graph to <strong>Inductor</strong> to compile into efficient kernels.</li></ol></li></ol><ol type="1" id="1c1c8bb5-c4a2-80ee-8c8f-d10977623e31" class="numbered-list" start="2"><li>Rewrite the bytecode of the function to call the <span style="border-bottom:0.05em solid">compiled function</span>.</li></ol><ol type="1" id="1c1c8bb5-c4a2-8096-904b-ee57e4de96db" class="numbered-list" start="3"><li>Give CPython the new bytecode to run.</li></ol><p id="1c1c8bb5-c4a2-8003-adbd-c3965a3f835b" class="">
</p><h3 id="1c1c8bb5-c4a2-804e-a1eb-f63f01cc290c" class=""><mark class="highlight-blue_background">Tracing</mark></h3><p id="1c1c8bb5-c4a2-8054-b50e-c94a37552a1d" class=""><strong>Dynamo is a tracer. </strong>Given function and inputs → returns FX graph.</p><p id="1c1c8bb5-c4a2-8074-9553-f1f853a48e14" class=""><strong>→ What’s an FX graph? </strong>Basically, a container storing a list of function calls. </p><p id="1c1c8bb5-c4a2-80aa-bc13-fb919fa18b9a" class=""><strong>→ What’s tracing?</strong></p><p id="1c1c8bb5-c4a2-80f2-af70-fac853319e01" class="">Follow a dummy input through the function, record linear sequence of PyTorch operations (DAG).</p><ul id="1c1c8bb5-c4a2-80c7-a13b-db26ff722113" class="bulleted-list"><li style="list-style-type:disc">Linear = no branching/control flow - only store the part of the if statement that was executed.</li></ul><ul id="1c1c8bb5-c4a2-80d0-9cd5-ff5f26497c41" class="bulleted-list"><li style="list-style-type:disc">Treats all non-tensor variables as constants (”specializes” these values). <ul id="1c1c8bb5-c4a2-808d-90b6-d62f16d232da" class="bulleted-list"><li style="list-style-type:circle">When a different shaped input enters, we retrace to create a new graph.</li></ul></li></ul><ul id="1c1c8bb5-c4a2-80c4-ac94-d322ba7904f7" class="bulleted-list"><li style="list-style-type:disc">Symbolic shapes: avoid retracing by marking an integer as dynamic (e.g. batch size).</li></ul><p id="1c1c8bb5-c4a2-803c-9c01-c830a62434f0" class="">
</p><h3 id="1c1c8bb5-c4a2-80ef-8691-dcd67f236bf8" class=""><mark class="highlight-blue_background">Frame Evaluation</mark></h3><p id="1c1c8bb5-c4a2-800c-9b66-f3430386d699" class=""><strong>How is it implemented?</strong></p><figure id="1c1c8bb5-c4a2-8020-87cc-c208c45d337c" class="image" style="text-align:left"><a href="images/image.png"><img style="width:624px" src="images/image.png"/></a></figure><p id="1c1c8bb5-c4a2-8056-a331-cc15eeb16253" class=""><strong>PEP523: </strong>Frame evaluation API</p><ul id="1c1c8bb5-c4a2-80da-9105-e611594e9b97" class="bulleted-list"><li style="list-style-type:disc">User can add custom per-function interpreter, which CPython will use for the function</li></ul><ul id="1c1c8bb5-c4a2-80a5-9e9e-f58b640744a1" class="bulleted-list"><li style="list-style-type:disc">CPython provides custom interpreter with function bytecode, argument values, names</li></ul><p id="1c1c8bb5-c4a2-80fb-979e-f36d56b8ad5e" class=""><strong>Dynamo + PEP523:</strong></p><ul id="1c1c8bb5-c4a2-80ba-a16b-ca1ce09db893" class="bulleted-list"><li style="list-style-type:disc">Dynamo = custom Python interpreter that runs the code and records the PyTorch operations<ul id="1c1c8bb5-c4a2-807f-ad06-de2a609b90fc" class="bulleted-list"><li style="list-style-type:circle">Call the backend (<strong>Inductor</strong>) to optimize the sequence of operations (graph)</li></ul></li></ul><ul id="1c1c8bb5-c4a2-803e-b9af-eaa683c6f73e" class="bulleted-list"><li style="list-style-type:disc">Packs the bytecode of the operations into a Python structure (VariableTracker)</li></ul><p id="1c1c8bb5-c4a2-80d3-99a6-f8190f9dddf1" class="">
</p><h3 id="1c1c8bb5-c4a2-80ce-ab69-ee4ab05168f3" class=""><mark class="highlight-blue_background">Guards</mark></h3><p id="1c1c8bb5-c4a2-80a8-aa5b-c87ebb38526f" class=""><strong>Problem: </strong>So what do we do about control flow? Tracing works if program is linear.</p><p id="1c1c8bb5-c4a2-8072-9c40-f5eeb33b8f28" class=""><strong>Guard: </strong>assumption made in order to specialize a frame for a set of inputs.</p><ul id="1c1c8bb5-c4a2-8046-a73c-cc7e5c0da33d" class="bulleted-list"><li style="list-style-type:disc">Graph can only be reused if assumption holds on new inputs</li></ul><ul id="1c1c8bb5-c4a2-8003-8142-c3878355477c" class="bulleted-list"><li style="list-style-type:disc">Accumulated during building phase (VariableTracker) and during execution</li></ul><p id="1c1c8bb5-c4a2-80f0-aca9-e9c2b9c6751b" class="">
</p><h3 id="1c1c8bb5-c4a2-8072-885a-e51ebc2ad3b1" class=""><mark class="highlight-blue_background">Symbolic Shapes</mark></h3><p id="1c1c8bb5-c4a2-80d5-bc4a-dd715feadac3" class="">Dynamo assumes static by default (no integers will be traced). </p><ul id="1c1c8bb5-c4a2-80bc-8f57-ee1f8c51b826" class="bulleted-list"><li style="list-style-type:disc">If it detects a shape/integer changed, it will trace and generate a <span style="border-bottom:0.05em solid">graph generic</span> (SymInt)</li></ul><ul id="1c1c8bb5-c4a2-8031-8212-f627eefa71ca" class="bulleted-list"><li style="list-style-type:disc">Duck shaping: if two dynamic integers have the same trace value, assume they are equal and guard on it (allows compiler fusions)</li></ul><p id="1c1c8bb5-c4a2-8091-97c9-cb8ad8911958" class="">This is why we need a custom interpreter.</p><ul id="1c1c8bb5-c4a2-8083-a1f2-d2a8f15f920a" class="bulleted-list"><li style="list-style-type:disc">Example:</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1c1c8bb5-c4a2-8000-9b08-c05f9705559a" class="code"><code class="language-Python">@torch.compile(dynamic=True)
def fn(a):
    if a.shape[0] * 2 &lt; 16:
        return a
    else:
        return a + 1

fn(torch.randn(8))</code></pre><ul id="1c1c8bb5-c4a2-8071-93f9-e7d7f15fc20d" class="bulleted-list"><li style="list-style-type:disc">Guard: <code>2*L[&#x27;a&#x27;].size()[0] &gt;= 16</code></li></ul><ul id="1c1c8bb5-c4a2-80d7-bad0-e955893f7f31" class="bulleted-list"><li style="list-style-type:disc">Cannot know this guard is needed until we get to the conditional on the symbolic argument</li></ul><ul id="1c1c8bb5-c4a2-80bf-b0ae-cca0935cda60" class="bulleted-list"><li style="list-style-type:disc">Requires analysis of the Python bytecode</li></ul><p id="1c1c8bb5-c4a2-80c5-a942-f68669d9257b" class="">
</p><h3 id="1c1c8bb5-c4a2-8089-aa3c-ed1a246775f8" class=""><mark class="highlight-blue_background">Graph Breaks</mark></h3><p id="1c1c8bb5-c4a2-8070-83a0-ebc52aa7790b" class=""><strong>How to handle “arbitrary Python code”</strong> (async, coroutines, external libraries, etc.)?</p><p id="1c1c8bb5-c4a2-808c-96b0-d4ba55ca0704" class=""><strong>Graph break:</strong> generate multiple graphs (before and after problematic code)</p><ul id="1c1c8bb5-c4a2-806a-a2de-c6687ee1122c" class="bulleted-list"><li style="list-style-type:disc">Delegate problematic code to CPython at runtime using CPython’s frame evaluation API</li></ul><p id="1c1c8bb5-c4a2-80b2-beb8-d2a14b80e7c2" class="">For code that is (graph1, problematic code, graph2), it returns:</p><ol type="1" id="1c1c8bb5-c4a2-80c2-ad92-e711e68b884c" class="numbered-list" start="1"><li>Bytecode that executes the <span style="border-bottom:0.05em solid">first graph</span></li></ol><ol type="1" id="1c1c8bb5-c4a2-80b0-85d2-c514f5baeb15" class="numbered-list" start="2"><li>Bytecode that <span style="border-bottom:0.05em solid">leaves the stack</span> as it would be if CPython would have executed the first graph (replays modifications to local or global variables)</li></ol><ol type="1" id="1c1c8bb5-c4a2-8059-99b2-fddffaf6ec65" class="numbered-list" start="3"><li>Bytecode that made Dynamo graph break (<span style="border-bottom:0.05em solid">raw problematic code</span>)</li></ol><ol type="1" id="1c1c8bb5-c4a2-8020-a4bd-eb2043504ede" class="numbered-list" start="4"><li>Bytecode that executes the <span style="border-bottom:0.05em solid">second graph</span></li></ol><h1 id="1c1c8bb5-c4a2-80f1-bc2e-f205f512369a" class=""><mark class="highlight-blue">2. Torch Inductor</mark></h1><p id="1c1c8bb5-c4a2-801c-87a1-d275812b80b8" class=""><strong>How do we compile the FX Graph that Dynamo traces?</strong></p><h3 id="1c1c8bb5-c4a2-8043-b3c7-e7ec8a7858ad" class=""><mark class="highlight-blue_background">Graph Lowering</mark></h3><p id="1c1c8bb5-c4a2-80df-ab6f-c5c1b0d4bfab" class="">Lower the FX graph into a <strong>fine-grained IR</strong> (intermediate representation).</p><ul id="1c1c8bb5-c4a2-809c-8942-d991c8dd62c2" class="bulleted-list"><li style="list-style-type:disc">Keep track of tensor operations / memory access patterns.</li></ul><ul id="1c1c8bb5-c4a2-8051-b49f-f5846c9ccd3d" class="bulleted-list"><li style="list-style-type:disc">Fuse together tensor computations to avoid unnecessary reads / writes.<ul id="1c1c8bb5-c4a2-800e-b940-e20fcf5d1de0" class="bulleted-list"><li style="list-style-type:circle">e.g., fuse <code>y = x * 2; z = y + 3</code> → <code>z = (x * 2) + 3</code> </li></ul></li></ul><ul id="1c1c8bb5-c4a2-806c-8da9-d9695f607964" class="bulleted-list"><li style="list-style-type:disc"><strong>Symbolic shapes: </strong>Use SymPy to track symbolic shapes<ul id="1c1c8bb5-c4a2-8081-8655-f07bc15c4402" class="bulleted-list"><li style="list-style-type:circle">Track the symbol through the entire program</li></ul><ul id="1c1c8bb5-c4a2-80e1-aa68-cf7704acb5cb" class="bulleted-list"><li style="list-style-type:circle">Memory accesses represented as symbolic indexing formulas dependent on inputs</li></ul><ul id="1c1c8bb5-c4a2-8010-9d27-d0aeec574c61" class="bulleted-list"><li style="list-style-type:circle">Create <span style="border-bottom:0.05em solid">guards</span> for assumptions on input shapes, trigger recompilation if guards fail</li></ul></li></ul><h3 id="1c1c8bb5-c4a2-8062-aa78-eb9b827f8fe5" class=""><mark class="highlight-blue_background">Graph Compiling</mark></h3><p id="1c1c8bb5-c4a2-8067-acdb-c8b1509019ab" class="">Fuse together kernels for tensor operations. </p><ul id="1c1c8bb5-c4a2-80be-ae28-cb337e811841" class="bulleted-list"><li style="list-style-type:disc">Original kernels: <code>kernel_1: sin(x)  -&gt;  kernel_2: mul(x, 2)  -&gt;  kernel_3: add(x, 1)</code> </li></ul><ul id="1c1c8bb5-c4a2-8027-a492-ddfe44068fb4" class="bulleted-list"><li style="list-style-type:disc">Fused kernel: <code>kernel_fused: result = (sin(x) * 2) + 1</code></li></ul><ul id="1c1c8bb5-c4a2-8006-808e-c090e38329a0" class="bulleted-list"><li style="list-style-type:disc">Generate Triton code for PyTorch operation kernels.<ul id="1c1c8bb5-c4a2-80f1-bab9-e607977d73a0" class="bulleted-list"><li style="list-style-type:circle">Optimized thread-block scheduling / block-wise memory access</li></ul><ul id="1c1c8bb5-c4a2-8019-becd-d7bf8dfbcfb5" class="bulleted-list"><li style="list-style-type:circle">Triton code gets JIT compiled into efficient PTX / CUDA binary (cubin) code</li></ul></li></ul><p id="1c1c8bb5-c4a2-80d8-92e2-fd5c08090d33" class="">
</p><p id="1c1c8bb5-c4a2-80ee-8e12-cc6c8a22f618" class="">This compiled Triton code is returned to Dynamo (and cached for subsequent runs).</p><p id="1c1c8bb5-c4a2-8081-b028-e3ce95980ae8" class="">The bytecode of the original function is <span style="border-bottom:0.05em solid">modified by Dynamo</span> to <strong>call the compiled kernels.</strong></p><h1 id="1c1c8bb5-c4a2-80e8-acc7-efe3757553b4" class=""><mark class="highlight-blue">3. CUDA Graphs</mark></h1><figure id="1c1c8bb5-c4a2-8086-a5c0-e4add51ec323" class="image"><a href="images/Screenshot_2025-03-24_at_8.43.28_PM.png"><img style="width:709.984375px" src="images/Screenshot_2025-03-24_at_8.43.28_PM.png"/></a></figure><p id="1c1c8bb5-c4a2-80da-8ee9-e147ba511f1a" class="">
</p><p id="1c1c8bb5-c4a2-8002-b450-f5fa011d9444" class=""><strong>Problem: </strong>CPU kernel launch overhead is inefficient.</p><ul id="1c1c8bb5-c4a2-8085-9c75-f019a63653f0" class="bulleted-list"><li style="list-style-type:disc">CPU launches creates gaps between kernels where GPU is idle</li></ul><p id="1c1c8bb5-c4a2-8058-8ba8-ce86ddf0a8bd" class="">
</p><p id="1c1c8bb5-c4a2-8009-bb12-c562d2197714" class="">Inductor has already fused together CUDA kernels at the <strong>IR level </strong>to make them more efficient.</p><ul id="1c1c8bb5-c4a2-803f-9f9b-f15e55915781" class="bulleted-list"><li style="list-style-type:disc">This is a <strong><span style="border-bottom:0.05em solid">compile-time </span></strong>optimization.</li></ul><ul id="1c1c8bb5-c4a2-809e-b457-fe56b3c85fef" class="bulleted-list"><li style="list-style-type:disc">But there’s still idle time between those kernels! We can still make <strong><span style="border-bottom:0.05em solid">run-time</span></strong><strong> </strong>optimizations.</li></ul><p id="1c1c8bb5-c4a2-801b-b03a-f1ffee7834dc" class="">
</p><p id="1c1c8bb5-c4a2-80ad-9b76-d2b27cef8038" class=""><strong>Solution: </strong>Capture sequences of kernels as CUDA Graph.</p><ul id="1c1c8bb5-c4a2-80cb-82e9-d0ef01d4c41f" class="bulleted-list"><li style="list-style-type:disc">Spend a fixed amount of time building CUDA graph at initialization</li></ul><ul id="1c1c8bb5-c4a2-8060-bf05-c45b94b539fa" class="bulleted-list"><li style="list-style-type:disc">At runtime, we can launch multiple kernels with a single CPU operation (minimal idle time)</li></ul><p id="1c1c8bb5-c4a2-80ff-b4b7-c1fa33412620" class="">
</p><p id="1c1c8bb5-c4a2-806d-8eaa-d838ae5a5450" class=""><strong>How? </strong>Using CUDA Stream capture.</p><ul id="1c1c8bb5-c4a2-80aa-9de5-d888dee1cdda" class="bulleted-list"><li style="list-style-type:disc">Create a graph from a section of code that launches work into streams<ul id="1c1c8bb5-c4a2-80a0-a41d-f91c692b7d7e" class="bulleted-list"><li style="list-style-type:circle">Instead of enqueuing work for execution, append to a graph</li></ul><ul id="1c1c8bb5-c4a2-8068-ab1b-d0b3de7ef7fa" class="bulleted-list"><li style="list-style-type:circle">Progressively build graph of kernel operations (without argument setup / kernel dispatch)</li></ul></li></ul><p id="1dcc8bb5-c4a2-80f4-97e7-d271f8389b5b" class="">
</p><p id="1dcc8bb5-c4a2-80bb-a5dd-c8529ef01b39" class="">At run-time, we can launch a batch of kernels together as a CUDA graph!</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span><script src="../../../js/notes-template.js"></script></body></html>